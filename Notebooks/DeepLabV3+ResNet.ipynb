{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw_-hFm6bjY6"
   },
   "source": [
    "## ðŸŒ Connect Colab to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2S4GWr3Uoa8",
    "outputId": "75d6284a-c942-4622-b5c3-0229f78b1d1e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/gdrive\")\n",
    "%cd /gdrive/My Drive\n",
    "%cd [2024-2025] AN2DL Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## âš™ï¸ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CO6_Ft_8T56A"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "tfk.config.enable_unsafe_deserialization()\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 29\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## â³ Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLaoDaG1V1Yg",
    "outputId": "f34e6e7f-f747-43e7-c217-47e009b830c9"
   },
   "outputs": [],
   "source": [
    "data = np.load(\"mars_for_students.npz\")\n",
    "\n",
    "training_set = data[\"training_set\"]\n",
    "X_train = training_set[:, 0]\n",
    "y_train = training_set[:, 1]\n",
    "\n",
    "X_test = data[\"test_set\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")\n",
    "\n",
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train = X_train[..., np.newaxis] / 255.0\n",
    "X_test = X_test[..., np.newaxis] / 255.0\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3VPMx3wpqVd"
   },
   "source": [
    "## ðŸ” Inspect the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Y5_2vtLTpufm"
   },
   "outputs": [],
   "source": [
    "# Calculate prevalent labels\n",
    "y_train_labels = mode(y_train, axis=(1, 2))[0].flatten()\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape}\")\n",
    "print(f\"Shape y_train_labels: {y_train_labels.shape}\")\n",
    "\n",
    "# List all unique labels to check correctness\n",
    "unique_labels = np.unique(y_train)\n",
    "print(f\"Unique classes: {unique_labels}\")\n",
    "\n",
    "# Plot images in batches\n",
    "def plot_images(X, y, start_index=0, images_per_row=10, images_per_col=10):\n",
    "    fig, axes = plt.subplots(images_per_col, images_per_row, figsize=(15, 15))\n",
    "    for i in range(images_per_row * images_per_col):\n",
    "        idx = start_index + i\n",
    "        if idx >= len(X):\n",
    "            break\n",
    "        ax = axes[i // images_per_row, i % images_per_row]\n",
    "        ax.imshow(X[idx], cmap=\"gray\")\n",
    "        ax.set_title(f\"Class: {y[idx]}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot a sample image from each class\n",
    "def plot_one_sample_per_class(X, y, y_mask, classes):\n",
    "    for label in classes:\n",
    "        for i in range(len(y_mask)):\n",
    "            if label in np.unique(y_mask[i]):\n",
    "                plt.figure()\n",
    "                plt.imshow(X[i], cmap=\"gray\")\n",
    "                plt.title(f\"Class: {label}\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                break\n",
    "\n",
    "plot_one_sample_per_class(X_train, y_train_labels, y_train, unique_labels)\n",
    "\n",
    "# Plot all images\n",
    "images_per_row = 10\n",
    "images_per_col = 10\n",
    "images_per_page = images_per_row * images_per_col\n",
    "num_images = X_train.shape[0]\n",
    "\n",
    "for start_idx in range(0, num_images, images_per_page):\n",
    "    plot_images(X_train, y_train_labels, start_index=start_idx, images_per_row=images_per_row, images_per_col=images_per_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z6VS98FeMBD"
   },
   "source": [
    "## âŒ Remove outliers from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PzVZbyNco6v",
    "outputId": "ff7137f4-44c7-4f11-9e6b-5d8af7f61d3f"
   },
   "outputs": [],
   "source": [
    "# Lists to contain filtered elements\n",
    "X_train_filtered = []\n",
    "y_train_filtered = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    label = y_train[i].argmax() if y_train.ndim > 1 else y_train[i]\n",
    "    if label != 415:\n",
    "        # Add to filtered dataset the non-alien images\n",
    "        X_train_filtered.append(X_train[i])\n",
    "        y_train_filtered.append(y_train[i])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train_filtered = np.array(X_train_filtered)\n",
    "y_train_filtered = np.array(y_train_filtered)\n",
    "\n",
    "print(f\"Shape X_train_filtered: {X_train_filtered.shape}\")\n",
    "print(f\"Shape y_train_filtered: {y_train_filtered.shape}\")\n",
    "print(f\"Unique classes: {np.unique(y_train_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fE76Lu-Ea0-"
   },
   "source": [
    "## ðŸ” Inspect the filtered training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ibagIaQkHRiK",
    "outputId": "791cda09-aefa-43f4-c7a5-e7da21f103bf"
   },
   "outputs": [],
   "source": [
    "num_images_filtered = X_train_filtered.shape[0]\n",
    "y_train_filtered_labels = mode(y_train_filtered, axis=(1, 2))[0].flatten()\n",
    "\n",
    "# Plot the filtered dataset\n",
    "for start_idx in range(0, num_images_filtered, images_per_page):\n",
    "    plot_images(X_train_filtered, y_train_filtered_labels, start_index=start_idx, images_per_row=images_per_row, images_per_col=images_per_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsXRC_eIlqdY"
   },
   "source": [
    "## ðŸ§® Define network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QB8MXxkwltdh"
   },
   "outputs": [],
   "source": [
    "# Set batch size for training\n",
    "batch_size = 64\n",
    "\n",
    "# Set learning rate for the optimiser\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Set early stopping patience threshold\n",
    "patience = 10\n",
    "\n",
    "# Set maximum number of training epochs\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEb5t0AgmfQc"
   },
   "source": [
    "## âœ‚ Split into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVf9fnTumtuP",
    "outputId": "22915f25-2746-46e6-c913-88849f63c07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:\t (2004, 64, 128, 1) (2004, 64, 128)\n",
      "Validation set shape:\t (501, 64, 128, 1) (501, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "# Split the training dataset to get a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_filtered,\n",
    "    y_train_filtered,\n",
    "    test_size=0.2,\n",
    "    random_state=seed)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print('Training set shape:\\t', X_train.shape, y_train.shape)\n",
    "print('Validation set shape:\\t', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVztd7_HgvOq"
   },
   "source": [
    "## ðŸ”„ Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_laNhjCPgxQo"
   },
   "outputs": [],
   "source": [
    "def augment_data(image, label):\n",
    "    # Geometric Transformations\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    label = tf.image.random_flip_left_right(label)\n",
    "\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    label = tf.image.random_flip_up_down(label)\n",
    "\n",
    "    # Chromatic Transformations\n",
    "    image = tf.image.random_brightness(image, max_delta=0.4)\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.expand_dims(image, axis=-1) if len(image.shape) == 2 else image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "def preprocess_label(label):\n",
    "    label = tf.expand_dims(label, axis=-1) if len(label.shape) == 2 else label\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    return label\n",
    "\n",
    "def preprocess_data(image, label):\n",
    "    image = preprocess_image(image)\n",
    "    label = preprocess_label(label)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EnFLkc1chG53"
   },
   "outputs": [],
   "source": [
    "# Dataset preprocessato (senza augmentation)\n",
    "train_dataset_static = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset_static = train_dataset_static.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset_static = train_dataset_static.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Dataset con augmentation\n",
    "train_dataset_dynamic = train_dataset_static.map(lambda x, y: augment_data(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Dataset combinato\n",
    "combined_dataset = train_dataset_static.concatenate(train_dataset_dynamic)\n",
    "combined_dataset = combined_dataset.shuffle(buffer_size=len(X_train))\n",
    "combined_dataset = combined_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzyhdlxCF2-X"
   },
   "source": [
    "## ðŸ” Plot Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883
    },
    "id": "BIprDuBhF3-p",
    "outputId": "692913ee-e0f8-46ff-d9f1-cf9c397420e9"
   },
   "outputs": [],
   "source": [
    "def plot_from_dataset(dataset, title, num_images=10):\n",
    "    # Imposta il layout orizzontale\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 3))\n",
    "    fig.suptitle(title, fontsize=16, y=1.05)\n",
    "    count = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        images, label_maps = batch  # Estrai immagini e feature map\n",
    "        for i in range(len(images)):\n",
    "            if count >= num_images:\n",
    "                break\n",
    "\n",
    "            # Prepara l'immagine\n",
    "            image = images[i].numpy()\n",
    "            if image.shape[-1] == 1:  # Scala di grigi\n",
    "                image = tf.squeeze(image, axis=-1).numpy()\n",
    "\n",
    "            # Mostra l'immagine\n",
    "            axes[count].imshow(image, cmap='gray' if image.ndim == 2 else None, aspect='auto')\n",
    "            axes[count].axis('off')\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if count >= num_images:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_from_dataset(train_dataset_static, \"Train Dataset without Augmentation\", num_images=10)\n",
    "plot_from_dataset(train_dataset_dynamic, \"Train Dataset with Augmentation\", num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYILwjHdlGNL"
   },
   "outputs": [],
   "source": [
    "def compare_datasets(dataset1, dataset2, index):\n",
    "    # Converti i dataset in liste di batch\n",
    "    dataset1_batches = list(dataset1)\n",
    "    dataset2_batches = list(dataset2)\n",
    "\n",
    "    # Determina l'indice del batch e l'indice all'interno del batch\n",
    "    batch_size = dataset1_batches[0][0].shape[0]  # Ottieni il batch size dal primo batch\n",
    "    batch_index = index // batch_size  # Batch contenente l'indice\n",
    "    within_batch_index = index % batch_size  # Indice all'interno del batch\n",
    "\n",
    "    # Estrai i batch corrispondenti\n",
    "    images1, masks1 = dataset1_batches[batch_index]\n",
    "    images2, masks2 = dataset2_batches[batch_index]\n",
    "\n",
    "    # Estrai l'immagine e la maschera all'interno del batch\n",
    "    img1, mask1 = images1[within_batch_index], masks1[within_batch_index]\n",
    "    img2, mask2 = images2[within_batch_index], masks2[within_batch_index]\n",
    "\n",
    "    # Converto i tensori in array numpy e rimuovo dimensioni non necessarie\n",
    "    img1 = img1.numpy().squeeze() if hasattr(img1, \"numpy\") else img1.squeeze()\n",
    "    mask1 = mask1.numpy().squeeze() if hasattr(mask1, \"numpy\") else mask1.squeeze()\n",
    "    img2 = img2.numpy().squeeze() if hasattr(img2, \"numpy\") else img2.squeeze()\n",
    "    mask2 = mask2.numpy().squeeze() if hasattr(mask2, \"numpy\") else mask2.squeeze()\n",
    "\n",
    "    # Usa una mappa di colori per le maschere\n",
    "    cmap = plt.get_cmap(\"tab20\")  # Mappa colori con 20 tonalitÃ  diverse\n",
    "    norm = plt.Normalize(vmin=0, vmax=np.max(mask1))  # Normalizza rispetto al valore massimo della maschera\n",
    "\n",
    "    # Crea la figura per il confronto\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(6, 12))  # Layout verticale\n",
    "\n",
    "    # Dataset1: Immagine\n",
    "    axes[0].imshow(img1, cmap='gray' if img1.ndim == 2 else None)\n",
    "    axes[0].set_title(f\"Image {index} (Original)\", fontsize=10)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Dataset1: Maschera colorata\n",
    "    axes[1].imshow(mask1, cmap=cmap, norm=norm)  # Maschera colorata\n",
    "    axes[1].set_title(f\"Mask {index} (Original)\", fontsize=10)\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Dataset2: Immagine\n",
    "    axes[2].imshow(img2, cmap='gray' if img2.ndim == 2 else None)\n",
    "    axes[2].set_title(f\"Image {index} (Augmented)\", fontsize=10)\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    # Dataset2: Maschera colorata\n",
    "    axes[3].imshow(mask2, cmap=cmap, norm=norm)  # Maschera colorata\n",
    "    axes[3].set_title(f\"Mask {index} (Augmented)\", fontsize=10)\n",
    "    axes[3].axis(\"off\")\n",
    "\n",
    "    # Mostra la figura\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_datasets(train_dataset_static, train_dataset_dynamic, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUpegWw8SLNr"
   },
   "source": [
    "## ðŸ”¨ Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e0EtfNnxhXTQ"
   },
   "outputs": [],
   "source": [
    "class InstanceNormalization(tfkl.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, variance = tf.nn.moments(inputs, axes=[1, 2], keepdims=True)\n",
    "        return (inputs - mean) / tf.sqrt(variance + 1e-5)\n",
    "\n",
    "class GroupNormalization(tfkl.Layer):\n",
    "    def __init__(self, groups=8, epsilon=1e-5, **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.groups = groups\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Ottieni la forma dinamica del tensore\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, height, width, channels = input_shape[0], input_shape[1], input_shape[2], input_shape[3]\n",
    "\n",
    "        # Controlla se i canali sono divisibili per i gruppi\n",
    "        remainder = tf.math.floormod(channels, self.groups)  # Calcola il resto\n",
    "        tf.debugging.assert_equal(remainder, 0, message=f\"Il numero di canali ({channels}) deve essere divisibile per il numero di gruppi ({self.groups}).\")\n",
    "\n",
    "        # Reshape per raggruppare i canali\n",
    "        group_shape = [batch_size, height, width, self.groups, channels // self.groups]\n",
    "        reshaped = tf.reshape(inputs, group_shape)\n",
    "\n",
    "        # Calcola media e varianza per normalizzazione\n",
    "        mean, variance = tf.nn.moments(reshaped, axes=[1, 2, 4], keepdims=True)\n",
    "        normalized = (reshaped - mean) / tf.sqrt(variance + self.epsilon)\n",
    "\n",
    "        # Ripristina la forma originale\n",
    "        output = tf.reshape(normalized, input_shape)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class ResizeLayer(Layer):\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.target_size[0], self.target_size[1], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bK5V0Oyf3Ec7"
   },
   "outputs": [],
   "source": [
    "def unet_block(input_tensor, filters, kernel_size=3, stack=2, name=''):\n",
    "    x = input_tensor\n",
    "    for i in range(stack):\n",
    "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "        x = GroupNormalization(groups=8)(x)\n",
    "        x = tfkl.Activation(tf.nn.leaky_relu)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(input_tensor, filters, kernel_size=3, growth_rate=32, num_layers=4):\n",
    "    x = input_tensor\n",
    "    for i in range(num_layers):\n",
    "        conv = tfkl.Conv2D(growth_rate, kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "        conv = tfkl.BatchNormalization()(conv)\n",
    "        conv = tfkl.Activation(tf.nn.leaky_relu)(conv)\n",
    "        x = tfkl.Concatenate()([x, conv])\n",
    "    return x\n",
    "\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = tfkl.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu')(input_tensor)\n",
    "    se = tfkl.GlobalAveragePooling2D()(se)\n",
    "    se = tfkl.Dense(filters // reduction_ratio, activation='relu', kernel_initializer='he_normal')(se)\n",
    "    se = tfkl.BatchNormalization()(se)\n",
    "    se = tfkl.Dense(filters, activation='sigmoid', kernel_initializer='he_normal')(se)\n",
    "    se = tfkl.Reshape((1, 1, filters))(se)\n",
    "    return tfkl.Multiply()([input_tensor, se])\n",
    "\n",
    "def refinement_block(x, filters):\n",
    "    for _ in range(2):  # Due livelli di raffinamento\n",
    "        x = tfkl.Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "        x = tfkl.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# Parallel Dilated Convolutions\n",
    "def par_dil_conv(input_tensor, filters, kernel_size=3, dilation_rates=(1, 2, 4)):\n",
    "    branches = []\n",
    "    for rate in dilation_rates:\n",
    "        branch = tfkl.Conv2D(filters, kernel_size=kernel_size, dilation_rate=rate, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(input_tensor)\n",
    "        branch = tfkl.BatchNormalization()(branch)\n",
    "        branch = tfkl.Activation(tf.nn.leaky_relu)(branch)\n",
    "        branches.append(branch)\n",
    "\n",
    "    # Concatenazione delle convoluzioni parallele\n",
    "    output = tfkl.Concatenate()(branches)\n",
    "    return output\n",
    "\n",
    "# Atrous Spatial Pyramid Pooling - alternativa a par_dil_conv\n",
    "def aspp(input_tensor, filters):\n",
    "    branch1 = tfkl.Conv2D(filters, kernel_size=1, padding='same', activation='relu')(input_tensor)\n",
    "    branch2 = tfkl.Conv2D(filters, kernel_size=3, dilation_rate=6, padding='same', activation='relu')(input_tensor)\n",
    "    branch3 = tfkl.Conv2D(filters, kernel_size=3, dilation_rate=12, padding='same', activation='relu')(input_tensor)\n",
    "    branch4 = tfkl.Conv2D(filters, kernel_size=3, dilation_rate=18, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "    # Pooling branch\n",
    "    pooling = tfkl.GlobalAveragePooling2D()(input_tensor)\n",
    "    pooling = tfkl.Reshape((1, 1, input_tensor.shape[-1]))(pooling)\n",
    "    pooling = tfkl.Conv2D(filters, kernel_size=1, padding='same', activation='relu')(pooling)\n",
    "    pooling = tfkl.UpSampling2D(size=(input_tensor.shape[1], input_tensor.shape[2]))(pooling)\n",
    "\n",
    "    output = tfkl.Concatenate()([branch1, branch2, branch3, branch4, pooling])\n",
    "    return tfkl.Conv2D(filters, kernel_size=1, padding='same', activation='relu')(output)\n",
    "\n",
    "def bottleneck_layer(input_tensor, filters, reduction_ratio=4, dilation_rates=None):\n",
    "    reduced_filters = filters // reduction_ratio\n",
    "    bottleneck = tfkl.SeparableConv2D(reduced_filters, kernel_size=3, padding='same', activation='relu')(input_tensor)\n",
    "    bottleneck = GroupNormalization(groups=8)(bottleneck)\n",
    "    bottleneck = se_block(bottleneck)\n",
    "    bottleneck = tfkl.SpatialDropout2D(0.3)(bottleneck)\n",
    "    return bottleneck\n",
    "\n",
    "def refinement_block(x, filters):\n",
    "    x = tfkl.Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2e2Mz9gUVbGd"
   },
   "outputs": [],
   "source": [
    "# Dice Loss\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    # Convert y_true to one-hot encoding\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes, axis=-1)\n",
    "\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "    return 1 - dice\n",
    "\n",
    "# Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Converte y_true in one-hot encoding\n",
    "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])\n",
    "        y_true_one_hot = tf.squeeze(y_true_one_hot, axis=-2) if len(y_true_one_hot.shape) > len(y_pred.shape) else y_true_one_hot\n",
    "\n",
    "        # Calcola la cross-entropy\n",
    "        cross_entropy = -y_true_one_hot * tf.keras.backend.log(y_pred)\n",
    "\n",
    "        # Applica il peso focale\n",
    "        weight = alpha * tf.math.pow((1 - y_pred), gamma)\n",
    "        loss = weight * cross_entropy\n",
    "\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n",
    "\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Combined Loss\n",
    "def combined_loss(y_true, y_pred, dice_weight=0.5, focal_weight=0.5):\n",
    "    # Calcola Dice Loss\n",
    "    dice = dice_loss(y_true, y_pred, smooth=1e-6)\n",
    "\n",
    "    # Calcola Focal Loss\n",
    "    focal = focal_loss(gamma=2.0, alpha=0.25)(y_true, y_pred)\n",
    "\n",
    "    # Combina le due loss\n",
    "    combined = dice_weight * dice + focal_weight * focal\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K94tOoPAKwdB"
   },
   "source": [
    "## Build DeepLabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVUHSrk8KyYT"
   },
   "outputs": [],
   "source": [
    "def aspp(inputs, filters=256, rate_scale=1):\n",
    "    # Controllo forma statica dell'input\n",
    "    input_shape = K.int_shape(inputs)  # (None, H, W, C)\n",
    "    H, W = input_shape[1], input_shape[2]\n",
    "\n",
    "    # Convoluzioni dilatate ASPP\n",
    "    x1 = tfkl.Conv2D(filters, 1, dilation_rate=1*rate_scale, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
    "    x2 = tfkl.Conv2D(filters, 3, dilation_rate=6*rate_scale, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
    "    x3 = tfkl.Conv2D(filters, 3, dilation_rate=12*rate_scale, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
    "    x4 = tfkl.Conv2D(filters, 3, dilation_rate=18*rate_scale, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
    "\n",
    "    # Global Average Pooling branch\n",
    "    x5 = tfkl.GlobalAveragePooling2D(keepdims=True)(inputs)  # (None,1,1,C)\n",
    "    x5 = tfkl.Conv2D(filters, 1, padding='same', activation='relu')(x5)\n",
    "\n",
    "    # Resize x5 a (H, W)\n",
    "    x5 = tfkl.Lambda(lambda x: tf.image.resize(x, (H, W), method='bilinear'),\n",
    "                     output_shape=(H, W, filters))(x5)\n",
    "\n",
    "    # Concatena tutte le feature map dell'ASPP\n",
    "    x = tfkl.Concatenate()([x1, x2, x3, x4, x5])\n",
    "    x = tfkl.Conv2D(filters, 1, padding='same', activation='relu')(x)\n",
    "    x = GroupNormalization(groups=8)(x)\n",
    "    x = tfkl.Dropout(0.3)(x)\n",
    "    return x\n",
    "\n",
    "def deeplabv3(input_shape, num_classes):\n",
    "    # Carica ResNet50 come encoder\n",
    "    backbone = tfk.applications.ResNet50(include_top=False, weights=None, input_shape=input_shape)\n",
    "\n",
    "    # Ottieni feature per skip connection\n",
    "    low_level_feature = backbone.get_layer('conv2_block3_out').output\n",
    "    high_level_feature = backbone.get_layer('conv4_block6_out').output\n",
    "\n",
    "    # Applica ASPP sul livello alto\n",
    "    aspp_out = aspp(high_level_feature, filters=256)\n",
    "\n",
    "    # Ottieni la forma statica del low_level_feature\n",
    "    low_shape = K.int_shape(low_level_feature)\n",
    "    LH, LW = low_shape[1], low_shape[2]\n",
    "\n",
    "    # Ridimensiona aspp_out alla dimensione di low_level_feature\n",
    "    aspp_out = tfkl.Lambda(lambda x: tf.image.resize(x, (LH, LW), method='bilinear'),\n",
    "                           output_shape=(LH, LW, 256))(aspp_out)\n",
    "\n",
    "    # Riduci dimensioni canali di low_level_feature\n",
    "    low_level_feature = tfkl.Conv2D(48, 1, padding='same', activation='relu')(low_level_feature)\n",
    "    low_level_feature = tfkl.BatchNormalization()(low_level_feature)\n",
    "\n",
    "    # Concatenazione\n",
    "    x = tfkl.Concatenate()([aspp_out, low_level_feature])\n",
    "\n",
    "    # Decoder\n",
    "    x = tfkl.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = GroupNormalization(groups=8)(x)\n",
    "    x = tfkl.Dropout(0.3)(x)\n",
    "    x = tfkl.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = GroupNormalization(groups=8)(x)\n",
    "    x = tfkl.Dropout(0.3)(x)\n",
    "\n",
    "    # Upsample finale alla dimensione di input\n",
    "    H, W = input_shape[0], input_shape[1]\n",
    "    x = tfkl.Lambda(lambda img: tf.image.resize(img, (H, W), method='bilinear'),\n",
    "                    output_shape=(H, W, 256))(x)\n",
    "\n",
    "    output = tfkl.Conv2D(num_classes, 1, padding='same', activation='softmax')(x)\n",
    "    model = tfk.Model(backbone.input, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "531k6YZ-LNC6"
   },
   "outputs": [],
   "source": [
    "inputs = tfkl.Input(shape=input_shape)\n",
    "\n",
    "deeplab = deeplabv3(input_shape=input_shape, num_classes=5)\n",
    "\n",
    "output = deeplab(inputs)\n",
    "\n",
    "# Modello finale\n",
    "model = tfk.Model(inputs, output)\n",
    "\n",
    "# Define the MeanIoU ignoring the background class\n",
    "mean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False, name='mean_iou')\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tfk.optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "loss = combined_loss\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[mean_iou]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## ðŸ› ï¸ Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stfBHdtb6kZa"
   },
   "outputs": [],
   "source": [
    "# Create an EarlyStopping callback\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_mean_iou',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Create a LearningRate Scheduler\n",
    "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5\n",
    ")\n",
    "\n",
    "# Store the callbacks in a list\n",
    "callbacks = [early_stopping, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMCbSMQ_-XoH"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    combined_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n",
    "print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PtM0ubgdOzG-"
   },
   "outputs": [],
   "source": [
    "timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "model_filename = f\"model_{timestep_str}.keras\"\n",
    "model.save(model_filename)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## ðŸ“Š Test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BU00iEFcYi_X",
    "outputId": "6451e379-7b48-48d5-868f-bdfdea247346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m314/314\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 57ms/step\n",
      "Predictions shape: (10022, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "model = tfk.models.load_model(model_filename, custom_objects={\n",
    "        \"ResizeLayer\": ResizeLayer,\n",
    "        \"InstanceNormalization\": InstanceNormalization,\n",
    "        \"GroupNormalization\": GroupNormalization,\n",
    "        'dice_loss': dice_loss,\n",
    "        'focal_loss': focal_loss,\n",
    "        'combined_loss': combined_loss,\n",
    "        'unet_block': unet_block,\n",
    "        'dense_block': dense_block,\n",
    "        'par_dil_conv': par_dil_conv,\n",
    "        'bottleneck_layer': bottleneck_layer,\n",
    "        'se_block': se_block\n",
    "    }\n",
    ")\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KErlLGwOTsX6"
   },
   "source": [
    "## ðŸ’¾ Save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SPjMEKqZW5jX"
   },
   "outputs": [],
   "source": [
    "def y_to_df(y) -> pd.DataFrame:\n",
    "    n_samples = len(y)\n",
    "    y_flat = y.reshape(n_samples, -1)\n",
    "    df = pd.DataFrame(y_flat)\n",
    "    df[\"id\"] = np.arange(n_samples)\n",
    "    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "s18kX1uDconq"
   },
   "outputs": [],
   "source": [
    "# Create the csv submission file\n",
    "timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n",
    "submission_filename = f\"submission_{timestep_str}.csv\"\n",
    "submission_df = y_to_df(preds)\n",
    "submission_df.to_csv(submission_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dw_-hFm6bjY6",
    "d7IqZP5Iblna",
    "GN_cpHlSboXV",
    "A3VPMx3wpqVd",
    "2z6VS98FeMBD",
    "9fE76Lu-Ea0-",
    "dsXRC_eIlqdY",
    "KEb5t0AgmfQc",
    "OVztd7_HgvOq",
    "PzyhdlxCF2-X",
    "vUpegWw8SLNr",
    "jCVur8U_3FWN",
    "RNp6pUZuddqC",
    "KErlLGwOTsX6"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
