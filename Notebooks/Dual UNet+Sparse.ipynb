{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw_-hFm6bjY6"
      },
      "source": [
        "## ğŸŒ Connect Colab to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2S4GWr3Uoa8",
        "outputId": "1055f673-80e0-480f-847f-c0e0242d935a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/[2024-2025] AN2DL Homework 2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")\n",
        "%cd /gdrive/My Drive\n",
        "%cd [2024-2025] AN2DL Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7IqZP5Iblna"
      },
      "source": [
        "## âš™ï¸ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CO6_Ft_8T56A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "tfk.config.enable_unsafe_deserialization()\n",
        "from tensorflow.keras import layers as tfkl\n",
        "from tensorflow.keras.layers import Layer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from scipy.stats import mode\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "seed = 29\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Set seed for TensorFlow\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Reduce TensorFlow verbosity\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_cpHlSboXV"
      },
      "source": [
        "## â³ Load the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLaoDaG1V1Yg",
        "outputId": "5ad51a72-a117-40d3-bd58-5cbf7bd26f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training X shape: (2615, 64, 128)\n",
            "Training y shape: (2615, 64, 128)\n",
            "Test X shape: (10022, 64, 128)\n",
            "Input shape: (64, 128, 1)\n",
            "Number of classes: 5\n"
          ]
        }
      ],
      "source": [
        "data = np.load(\"mars_for_students.npz\")\n",
        "\n",
        "training_set = data[\"training_set\"]\n",
        "X_train = training_set[:, 0]\n",
        "y_train = training_set[:, 1]\n",
        "\n",
        "X_test = data[\"test_set\"]\n",
        "\n",
        "print(f\"Training X shape: {X_train.shape}\")\n",
        "print(f\"Training y shape: {y_train.shape}\")\n",
        "print(f\"Test X shape: {X_test.shape}\")\n",
        "\n",
        "# Add color channel and rescale pixels between 0 and 1\n",
        "X_train = X_train[..., np.newaxis] / 255.0\n",
        "X_test = X_test[..., np.newaxis] / 255.0\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "print(f\"Input shape: {input_shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3VPMx3wpqVd"
      },
      "source": [
        "## ğŸ” Inspect the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y5_2vtLTpufm",
        "outputId": "062249fd-b185-4388-c2f7-0cfd45ecd79c"
      },
      "outputs": [],
      "source": [
        "# Calculate prevalent labels\n",
        "y_train_labels = mode(y_train, axis=(1, 2))[0].flatten()\n",
        "\n",
        "print(f\"Shape X_train: {X_train.shape}\")\n",
        "print(f\"Shape y_train_labels: {y_train_labels.shape}\")\n",
        "\n",
        "# List all unique labels to check correctness\n",
        "unique_labels = np.unique(y_train)\n",
        "print(f\"Unique classes: {unique_labels}\")\n",
        "\n",
        "# Plot images in batches\n",
        "def plot_images(X, y, start_index=0, images_per_row=10, images_per_col=10):\n",
        "    fig, axes = plt.subplots(images_per_col, images_per_row, figsize=(15, 15))\n",
        "    for i in range(images_per_row * images_per_col):\n",
        "        idx = start_index + i\n",
        "        if idx >= len(X):\n",
        "            break\n",
        "        ax = axes[i // images_per_row, i % images_per_row]\n",
        "        ax.imshow(X[idx], cmap=\"gray\")\n",
        "        ax.set_title(f\"Class: {y[idx]}\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot a sample image from each class\n",
        "def plot_one_sample_per_class(X, y, y_mask, classes):\n",
        "    for label in classes:\n",
        "        for i in range(len(y_mask)):\n",
        "            if label in np.unique(y_mask[i]):\n",
        "                plt.figure()\n",
        "                plt.imshow(X[i], cmap=\"gray\")\n",
        "                plt.title(f\"Class: {label}\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.show()\n",
        "                break\n",
        "\n",
        "plot_one_sample_per_class(X_train, y_train_labels, y_train, unique_labels)\n",
        "\n",
        "# Plot all images\n",
        "images_per_row = 10\n",
        "images_per_col = 10\n",
        "images_per_page = images_per_row * images_per_col\n",
        "num_images = X_train.shape[0]\n",
        "\n",
        "for start_idx in range(0, num_images, images_per_page):\n",
        "    plot_images(X_train, y_train_labels, start_index=start_idx, images_per_row=images_per_row, images_per_col=images_per_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z6VS98FeMBD"
      },
      "source": [
        "## âŒ Remove outliers from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PzVZbyNco6v",
        "outputId": "4b693182-8130-4ac5-eaa1-6dce7e8d6363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X_train_filtered: (2505, 64, 128, 1)\n",
            "Shape y_train_filtered: (2505, 64, 128)\n",
            "Unique classes: [0. 1. 2. 3. 4.]\n"
          ]
        }
      ],
      "source": [
        "# Lists to contain filtered elements\n",
        "X_train_filtered = []\n",
        "y_train_filtered = []\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "    label = y_train[i].argmax() if y_train.ndim > 1 else y_train[i]\n",
        "    if label != 415:\n",
        "        # Add to filtered dataset the non-alien images\n",
        "        X_train_filtered.append(X_train[i])\n",
        "        y_train_filtered.append(y_train[i])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train_filtered = np.array(X_train_filtered)\n",
        "y_train_filtered = np.array(y_train_filtered)\n",
        "\n",
        "print(f\"Shape X_train_filtered: {X_train_filtered.shape}\")\n",
        "print(f\"Shape y_train_filtered: {y_train_filtered.shape}\")\n",
        "print(f\"Unique classes: {np.unique(y_train_filtered)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fE76Lu-Ea0-"
      },
      "source": [
        "## ğŸ” Inspect the filtered training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ibagIaQkHRiK",
        "outputId": "791cda09-aefa-43f4-c7a5-e7da21f103bf"
      },
      "outputs": [],
      "source": [
        "num_images_filtered = X_train_filtered.shape[0]\n",
        "y_train_filtered_labels = mode(y_train_filtered, axis=(1, 2))[0].flatten()\n",
        "\n",
        "# Plot the filtered dataset\n",
        "for start_idx in range(0, num_images_filtered, images_per_page):\n",
        "    plot_images(X_train_filtered, y_train_filtered_labels, start_index=start_idx, images_per_row=images_per_row, images_per_col=images_per_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsXRC_eIlqdY"
      },
      "source": [
        "## ğŸ§® Define network parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB8MXxkwltdh"
      },
      "outputs": [],
      "source": [
        "# Set batch size for training\n",
        "batch_size = 64\n",
        "\n",
        "# Set learning rate for the optimizer\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Set early stopping patience threshold\n",
        "patience = 15\n",
        "\n",
        "# Set maximum number of training epochs\n",
        "epochs = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te5Ey7pNoeiw"
      },
      "outputs": [],
      "source": [
        "# Create an EarlyStopping callback\n",
        "early_stopping = tfk.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=patience,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Create a LearningRate Scheduler, which reduces learning rate if val_loss doesn't improve\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5\n",
        ")\n",
        "\n",
        "# Store the callback in a list\n",
        "callbacks = [early_stopping, lr_scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEb5t0AgmfQc"
      },
      "source": [
        "## âœ‚ Split into Training and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVf9fnTumtuP",
        "outputId": "1c288161-3428-40e1-9c0d-98a5ccc38998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape:\t (2254, 64, 128, 1) (2254, 64, 128)\n",
            "Validation set shape:\t (251, 64, 128, 1) (251, 64, 128)\n",
            "Class weights:\t [0.8176698618113929, 0.5910939761597104, 0.8421959857784994, 1.1219193842338118, 153.08214226496435]\n"
          ]
        }
      ],
      "source": [
        "# Split the training dataset to get a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_filtered,\n",
        "    y_train_filtered,\n",
        "    test_size=0.1,\n",
        "    random_state=seed)\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "class_weights = [class_weights[key] for key in sorted(class_weights.keys())]\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print('Training set shape:\\t', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:\\t', X_val.shape, y_val.shape)\n",
        "print('Class weights:\\t', class_weights)\n",
        "\n",
        "# Convert in un tensore statico\n",
        "class_weights = tf.constant(class_weights, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVztd7_HgvOq"
      },
      "source": [
        "## ğŸ”„ Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_laNhjCPgxQo"
      },
      "outputs": [],
      "source": [
        "def augment_data(image, label):\n",
        "    # Geometric Transformations\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    label = tf.image.random_flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    label = tf.image.random_flip_up_down(label)\n",
        "\n",
        "    # Chromatic Transformations\n",
        "    image = tf.image.random_brightness(image, max_delta=0.4)\n",
        "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = tf.expand_dims(image, axis=-1) if len(image.shape) == 2 else image\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "def preprocess_label(label):\n",
        "    label = tf.expand_dims(label, axis=-1) if len(label.shape) == 2 else label\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    return label\n",
        "\n",
        "def preprocess_data(image, label):\n",
        "    image = preprocess_image(image)\n",
        "    label = preprocess_label(label)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnFLkc1chG53"
      },
      "outputs": [],
      "source": [
        "# Original dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Augmented dataset\n",
        "augmented_dataset = train_dataset.map(lambda x, y: augment_data(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Combined dataset, having both augmented and original dataset\n",
        "combined_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "combined_dataset = combined_dataset.shuffle(buffer_size=len(X_train))\n",
        "combined_dataset = combined_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation dataset\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzyhdlxCF2-X"
      },
      "source": [
        "## ğŸ” Plot Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "BIprDuBhF3-p",
        "outputId": "692913ee-e0f8-46ff-d9f1-cf9c397420e9"
      },
      "outputs": [],
      "source": [
        "def plot_from_dataset(dataset, title, num_images=10):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 3))\n",
        "    fig.suptitle(title, fontsize=16, y=1.05)\n",
        "    count = 0\n",
        "\n",
        "    for batch in dataset:\n",
        "        images, label_maps = batch\n",
        "        for i in range(len(images)):\n",
        "            if count >= num_images:\n",
        "                break\n",
        "            image = images[i].numpy()\n",
        "            if image.shape[-1] == 1:\n",
        "                image = tf.squeeze(image, axis=-1).numpy()\n",
        "            axes[count].imshow(image, cmap='gray' if image.ndim == 2 else None, aspect='auto')\n",
        "            axes[count].axis('off')\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        if count >= num_images:\n",
        "            break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_from_dataset(train_dataset, \"Train Dataset without Augmentation\", num_images=10)\n",
        "plot_from_dataset(augmented_dataset, \"Train Dataset with Augmentation\", num_images=10)\n",
        "plot_from_dataset(combined_dataset, \"Combined Dataset\", num_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUpegWw8SLNr"
      },
      "source": [
        "## ğŸ”¨ Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH96h-n22oOo"
      },
      "outputs": [],
      "source": [
        "def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
        "    # Residual connection\n",
        "    residual = input_tensor\n",
        "    residual = tfkl.Conv2D(filters, kernel_size=1, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(residual)\n",
        "\n",
        "    # Convolutional path\n",
        "    x = input_tensor\n",
        "    for i in range(stack):\n",
        "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "        x = tfkl.BatchNormalization()(x)\n",
        "        x = tfkl.Activation(activation)(x)\n",
        "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "        x = tfkl.BatchNormalization()(x)\n",
        "        x = tfkl.Activation(activation)(x)\n",
        "        x = tfkl.SpatialDropout2D(0.2)(x)\n",
        "\n",
        "    # Add residual connection\n",
        "    x = tfkl.Add()([x, residual])\n",
        "    return x\n",
        "\n",
        "def dense_block(input_tensor, filters, kernel_size=3, growth_rate=32, num_layers=4):\n",
        "    x = input_tensor\n",
        "    for i in range(num_layers):\n",
        "        conv = tfkl.Conv2D(growth_rate, kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "        conv = tfkl.BatchNormalization()(conv)\n",
        "        conv = tfkl.Activation('relu')(conv)\n",
        "        x = tfkl.Concatenate()([x, conv])\n",
        "    return x\n",
        "\n",
        "def par_dil_conv(input_tensor, filters, kernel_size=3, dilation_rates=(1, 2, 4), activation='relu'):\n",
        "    branches = []\n",
        "    for rate in dilation_rates:\n",
        "        branch = tfkl.Conv2D(filters, kernel_size=kernel_size, dilation_rate=rate, padding='same',\n",
        "                             kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(input_tensor)\n",
        "        branch = tfkl.BatchNormalization()(branch)\n",
        "        branch = tfkl.Activation(activation)(branch)\n",
        "        branches.append(branch)\n",
        "    output = tfkl.Concatenate()(branches)\n",
        "    output = tfkl.Conv2D(filters, kernel_size=1, padding='same', kernel_initializer='he_normal')(output)\n",
        "    return output\n",
        "\n",
        "def bottleneck_layer(input_tensor, filters, reduction_ratio=4, dilation_rates=(1, 2, 4)):\n",
        "    # Compression\n",
        "    reduced_filters = filters // reduction_ratio\n",
        "    bottleneck = tfkl.Conv2D(reduced_filters, kernel_size=1, padding='same', activation='relu')(input_tensor)\n",
        "\n",
        "    # Parallel Dilated Convolutions\n",
        "    bottleneck = par_dil_conv(bottleneck, filters=reduced_filters, dilation_rates=dilation_rates)\n",
        "\n",
        "    # Expansion\n",
        "    bottleneck = tfkl.Conv2D(filters, kernel_size=3, padding='same', activation='relu')(bottleneck)\n",
        "    return bottleneck\n",
        "\n",
        "def se_block(input_tensor, reduction_ratio=16):\n",
        "    filters = input_tensor.shape[-1]\n",
        "    se = tfkl.GlobalAveragePooling2D()(input_tensor)\n",
        "    se = tfkl.Dense(filters // reduction_ratio, activation='relu')(se)\n",
        "    se = tfkl.Dense(filters, activation='sigmoid')(se)\n",
        "    se = tfkl.Reshape((1, 1, filters))(se)\n",
        "    return tfkl.Multiply()([input_tensor, se])\n",
        "\n",
        "# Class to downsize a tensor\n",
        "class DownsizeLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.image.resize(inputs, (32, 64))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], 32, 64, input_shape[-1])\n",
        "\n",
        "# Class to upsize a tensor\n",
        "class UpsizeLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.image.resize(inputs, (64, 128))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], 64, 128, input_shape[-1])\n",
        "\n",
        "# Function to create a UNet\n",
        "def create_unet(input_shape, num_classes):\n",
        "  input_layer = tfkl.Input(shape=input_shape)\n",
        "\n",
        "  # Downsampling path\n",
        "  down_block_1 = dense_block(input_layer, filters=32, growth_rate=16, num_layers=3)\n",
        "  d1 = tfkl.Conv2D(32, (3, 3), strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(1e-4))(down_block_1)\n",
        "\n",
        "  down_block_2 = dense_block(d1, filters=64, growth_rate=16, num_layers=3)\n",
        "  d2 = tfkl.Conv2D(64, (3, 3), strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(1e-4))(down_block_2)\n",
        "\n",
        "  # Bottleneck con Parallel Dilated Convolutions\n",
        "  bottleneck = bottleneck_layer(d2, filters=128, dilation_rates=(1, 2, 4))\n",
        "  bottleneck = se_block(bottleneck)\n",
        "\n",
        "  # Upsampling path\n",
        "  u1 = tfkl.Conv2DTranspose(64, kernel_size=2, strides=2, padding='same')(bottleneck)\n",
        "  u1 = tfkl.Concatenate()([u1, se_block(down_block_2)])\n",
        "  u1 = unet_block(u1, 64, name='up_block1_')\n",
        "\n",
        "  u2 = tfkl.Conv2DTranspose(32, kernel_size=2, strides=2, padding='same')(u1)\n",
        "  u2 = tfkl.Concatenate()([u2, se_block(down_block_1)])\n",
        "  u2 = unet_block(u2, 32, name='up_block2_')\n",
        "\n",
        "  # Output Layer\n",
        "  output_layer = se_block(u2)\n",
        "  output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\")(output_layer)\n",
        "\n",
        "  return tfk.Model(inputs=input_layer, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e2Mz9gUVbGd"
      },
      "outputs": [],
      "source": [
        "# Dice Loss\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    if len(y_true.shape) < len(y_pred.shape):\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])\n",
        "\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    tf.debugging.assert_equal(\n",
        "    tf.shape(y_true),\n",
        "    tf.shape(y_pred),\n",
        "    message=\"Shape mismatch: y_true and y_pred have different shapes.\"\n",
        ")\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return 1 - ((2. * intersection + smooth) /\n",
        "                (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth))\n",
        "\n",
        "# Focal Loss\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
        "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])\n",
        "        y_true_one_hot = tf.squeeze(y_true_one_hot, axis=-2) if len(y_true_one_hot.shape) > len(y_pred.shape) else y_true_one_hot\n",
        "        cross_entropy = -y_true_one_hot * tf.keras.backend.log(y_pred)\n",
        "        weight = alpha * tf.math.pow((1 - y_pred), gamma)\n",
        "        loss = weight * cross_entropy\n",
        "        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n",
        "\n",
        "    return focal_loss_fixed\n",
        "\n",
        "def weighted_loss(y_true, y_pred):\n",
        "    global class_weights\n",
        "    weights_per_pixel = tf.gather(class_weights, tf.cast(y_true, tf.int32))\n",
        "    weights_per_pixel = tf.expand_dims(weights_per_pixel, axis=-1)\n",
        "    weights_per_pixel = tf.squeeze(weights_per_pixel, axis=-1)\n",
        "\n",
        "    # Calculate SparseCategoricalCrossentropy\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
        "    unweighted_loss = scce(y_true, y_pred)\n",
        "\n",
        "    # To match dimensions\n",
        "    unweighted_loss = tf.expand_dims(unweighted_loss, axis=-1)\n",
        "\n",
        "    weighted_loss = unweighted_loss * weights_per_pixel\n",
        "\n",
        "    # Media finale\n",
        "    return tf.reduce_mean(weighted_loss)\n",
        "\n",
        "focal = focal_loss(gamma=2.0, alpha=0.25)\n",
        "\n",
        "# Combined Loss\n",
        "def combined_loss_wrapper():\n",
        "    def combined_loss(y_true, y_pred):\n",
        "\n",
        "        # Dice Loss\n",
        "        d_loss = dice_loss(y_true, y_pred)\n",
        "\n",
        "        # Focal Loss\n",
        "        f_loss = focal(y_true, y_pred)\n",
        "\n",
        "        return d_loss + f_loss\n",
        "\n",
        "    return combined_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CBkb3TRF1KJx"
      },
      "outputs": [],
      "source": [
        "downsize_layer = DownsizeLayer()\n",
        "upsize_layer = UpsizeLayer()\n",
        "\n",
        "# Global UNet\n",
        "input_shape_global = (32, 64, 1)\n",
        "unet_global = create_unet(input_shape_global, num_classes)\n",
        "\n",
        "# Local UNet\n",
        "unet_local = create_unet(input_shape, num_classes)\n",
        "\n",
        "# Input\n",
        "inputs = tfkl.Input(shape=input_shape)\n",
        "\n",
        "global_input = downsize_layer(inputs)\n",
        "global_features = unet_global(global_input)\n",
        "\n",
        "local_features = unet_local(inputs)\n",
        "\n",
        "# Features fusion from both nets\n",
        "global_upsampled = upsize_layer(global_features) # Upsize to match dimensions\n",
        "fused_features = tfkl.Concatenate()([global_upsampled, local_features])\n",
        "\n",
        "output = tfkl.Conv2D(num_classes, kernel_size=3, padding='same', activation='softmax')(fused_features)\n",
        "\n",
        "model = tfk.Model(inputs, output)\n",
        "\n",
        "# Define the MeanIoU ignoring the background class\n",
        "mean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False, name='mean_iou')\n",
        "optimizer = tfk.optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-5)\n",
        "loss = tfk.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=[mean_iou]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSliIxBvbs2Q"
      },
      "source": [
        "## ğŸ› ï¸ Train and Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMCbSMQ_-XoH",
        "outputId": "1cedd823-255e-42bb-c239-12ad25c5cf10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 255ms/step - loss: 1.3270 - mean_iou: 0.3300 - val_loss: 1.4378 - val_mean_iou: 0.2835 - learning_rate: 1.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 257ms/step - loss: 1.2675 - mean_iou: 0.3568 - val_loss: 1.3469 - val_mean_iou: 0.3090 - learning_rate: 1.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 253ms/step - loss: 1.2201 - mean_iou: 0.3757 - val_loss: 1.3204 - val_mean_iou: 0.3288 - learning_rate: 1.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 249ms/step - loss: 1.2003 - mean_iou: 0.3723 - val_loss: 1.3130 - val_mean_iou: 0.3208 - learning_rate: 1.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - loss: 1.1675 - mean_iou: 0.3821 - val_loss: 1.1661 - val_mean_iou: 0.3776 - learning_rate: 1.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 254ms/step - loss: 1.1552 - mean_iou: 0.3767 - val_loss: 1.2175 - val_mean_iou: 0.3526 - learning_rate: 1.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 253ms/step - loss: 1.1380 - mean_iou: 0.3845 - val_loss: 1.1190 - val_mean_iou: 0.3902 - learning_rate: 1.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 252ms/step - loss: 1.0953 - mean_iou: 0.3971 - val_loss: 1.1879 - val_mean_iou: 0.3213 - learning_rate: 1.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - loss: 1.0956 - mean_iou: 0.3821 - val_loss: 1.1199 - val_mean_iou: 0.4057 - learning_rate: 1.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 251ms/step - loss: 1.0619 - mean_iou: 0.4121 - val_loss: 1.1328 - val_mean_iou: 0.3795 - learning_rate: 1.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 261ms/step - loss: 1.0640 - mean_iou: 0.4006 - val_loss: 1.0721 - val_mean_iou: 0.3916 - learning_rate: 1.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 250ms/step - loss: 1.0430 - mean_iou: 0.4034 - val_loss: 1.0788 - val_mean_iou: 0.3970 - learning_rate: 1.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 250ms/step - loss: 1.0321 - mean_iou: 0.4091 - val_loss: 1.0852 - val_mean_iou: 0.3889 - learning_rate: 1.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - loss: 1.0414 - mean_iou: 0.4048 - val_loss: 1.0264 - val_mean_iou: 0.4121 - learning_rate: 1.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - loss: 1.0307 - mean_iou: 0.4021 - val_loss: 1.0931 - val_mean_iou: 0.3602 - learning_rate: 1.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 251ms/step - loss: 0.9979 - mean_iou: 0.4152 - val_loss: 1.0102 - val_mean_iou: 0.4083 - learning_rate: 1.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 253ms/step - loss: 0.9899 - mean_iou: 0.4140 - val_loss: 1.0021 - val_mean_iou: 0.4291 - learning_rate: 1.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - loss: 0.9919 - mean_iou: 0.4175 - val_loss: 1.0526 - val_mean_iou: 0.3769 - learning_rate: 1.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - loss: 0.9759 - mean_iou: 0.4183 - val_loss: 1.0872 - val_mean_iou: 0.3662 - learning_rate: 1.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 253ms/step - loss: 0.9618 - mean_iou: 0.4207 - val_loss: 1.1900 - val_mean_iou: 0.3470 - learning_rate: 1.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 253ms/step - loss: 0.9722 - mean_iou: 0.4176 - val_loss: 1.0003 - val_mean_iou: 0.4154 - learning_rate: 1.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 254ms/step - loss: 0.9356 - mean_iou: 0.4302 - val_loss: 0.9686 - val_mean_iou: 0.4269 - learning_rate: 1.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 250ms/step - loss: 0.9304 - mean_iou: 0.4292 - val_loss: 1.0343 - val_mean_iou: 0.4035 - learning_rate: 1.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - loss: 0.9709 - mean_iou: 0.4131 - val_loss: 0.9570 - val_mean_iou: 0.4328 - learning_rate: 1.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 249ms/step - loss: 0.9405 - mean_iou: 0.4228 - val_loss: 1.0380 - val_mean_iou: 0.3912 - learning_rate: 1.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.9152 - mean_iou: 0.4403 - val_loss: 1.0320 - val_mean_iou: 0.3921 - learning_rate: 1.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 255ms/step - loss: 0.9003 - mean_iou: 0.4378 - val_loss: 0.9448 - val_mean_iou: 0.4420 - learning_rate: 1.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 253ms/step - loss: 0.8970 - mean_iou: 0.4405 - val_loss: 0.9363 - val_mean_iou: 0.4426 - learning_rate: 1.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - loss: 0.8790 - mean_iou: 0.4479 - val_loss: 0.9923 - val_mean_iou: 0.3871 - learning_rate: 1.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 250ms/step - loss: 0.8958 - mean_iou: 0.4374 - val_loss: 0.9537 - val_mean_iou: 0.4272 - learning_rate: 1.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - loss: 0.8685 - mean_iou: 0.4497 - val_loss: 0.9781 - val_mean_iou: 0.4334 - learning_rate: 1.0000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 255ms/step - loss: 0.8655 - mean_iou: 0.4529 - val_loss: 0.9248 - val_mean_iou: 0.4380 - learning_rate: 1.0000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 252ms/step - loss: 0.8601 - mean_iou: 0.4461 - val_loss: 0.9569 - val_mean_iou: 0.4339 - learning_rate: 1.0000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - loss: 0.8430 - mean_iou: 0.4574 - val_loss: 0.9287 - val_mean_iou: 0.4424 - learning_rate: 1.0000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 249ms/step - loss: 0.8571 - mean_iou: 0.4544 - val_loss: 1.0017 - val_mean_iou: 0.3887 - learning_rate: 1.0000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 252ms/step - loss: 0.8567 - mean_iou: 0.4443 - val_loss: 0.9763 - val_mean_iou: 0.4220 - learning_rate: 1.0000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 253ms/step - loss: 0.8547 - mean_iou: 0.4514 - val_loss: 0.9700 - val_mean_iou: 0.4245 - learning_rate: 1.0000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - loss: 0.8199 - mean_iou: 0.4625 - val_loss: 0.9200 - val_mean_iou: 0.4342 - learning_rate: 5.0000e-05\n",
            "Epoch 39/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.8111 - mean_iou: 0.4637 - val_loss: 0.9220 - val_mean_iou: 0.4309 - learning_rate: 5.0000e-05\n",
            "Epoch 40/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 253ms/step - loss: 0.8072 - mean_iou: 0.4653 - val_loss: 0.9234 - val_mean_iou: 0.4458 - learning_rate: 5.0000e-05\n",
            "Epoch 41/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 254ms/step - loss: 0.7796 - mean_iou: 0.4727 - val_loss: 0.9027 - val_mean_iou: 0.4492 - learning_rate: 5.0000e-05\n",
            "Epoch 42/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 254ms/step - loss: 0.8077 - mean_iou: 0.4611 - val_loss: 0.9197 - val_mean_iou: 0.4407 - learning_rate: 5.0000e-05\n",
            "Epoch 43/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.7930 - mean_iou: 0.4693 - val_loss: 0.9052 - val_mean_iou: 0.4439 - learning_rate: 5.0000e-05\n",
            "Epoch 44/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.7843 - mean_iou: 0.4666 - val_loss: 0.9421 - val_mean_iou: 0.4269 - learning_rate: 5.0000e-05\n",
            "Epoch 45/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 252ms/step - loss: 0.7489 - mean_iou: 0.4795 - val_loss: 0.9618 - val_mean_iou: 0.4267 - learning_rate: 5.0000e-05\n",
            "Epoch 46/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 254ms/step - loss: 0.7773 - mean_iou: 0.4710 - val_loss: 0.9246 - val_mean_iou: 0.4409 - learning_rate: 5.0000e-05\n",
            "Epoch 47/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - loss: 0.7516 - mean_iou: 0.4833 - val_loss: 0.9134 - val_mean_iou: 0.4481 - learning_rate: 2.5000e-05\n",
            "Epoch 48/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 250ms/step - loss: 0.7629 - mean_iou: 0.4810 - val_loss: 0.9193 - val_mean_iou: 0.4367 - learning_rate: 2.5000e-05\n",
            "Epoch 49/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - loss: 0.7445 - mean_iou: 0.4835 - val_loss: 0.9108 - val_mean_iou: 0.4466 - learning_rate: 2.5000e-05\n",
            "Epoch 50/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - loss: 0.7408 - mean_iou: 0.4818 - val_loss: 0.9125 - val_mean_iou: 0.4394 - learning_rate: 2.5000e-05\n",
            "Epoch 51/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 251ms/step - loss: 0.7498 - mean_iou: 0.4777 - val_loss: 0.9310 - val_mean_iou: 0.4371 - learning_rate: 2.5000e-05\n",
            "Epoch 52/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - loss: 0.7499 - mean_iou: 0.4783 - val_loss: 0.9065 - val_mean_iou: 0.4460 - learning_rate: 1.2500e-05\n",
            "Epoch 53/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.7675 - mean_iou: 0.4722 - val_loss: 0.9179 - val_mean_iou: 0.4496 - learning_rate: 1.2500e-05\n",
            "Epoch 54/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 251ms/step - loss: 0.7529 - mean_iou: 0.4771 - val_loss: 0.9059 - val_mean_iou: 0.4503 - learning_rate: 1.2500e-05\n",
            "Epoch 55/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.7361 - mean_iou: 0.4822 - val_loss: 0.9072 - val_mean_iou: 0.4467 - learning_rate: 1.2500e-05\n",
            "Epoch 56/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - loss: 0.7294 - mean_iou: 0.4870 - val_loss: 0.9147 - val_mean_iou: 0.4491 - learning_rate: 1.2500e-05\n",
            "Final validation Mean Intersection Over Union: 45.03%\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    combined_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks\n",
        ").history\n",
        "\n",
        "# Calculate and print the final validation accuracy\n",
        "final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n",
        "print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtM0ubgdOzG-"
      },
      "outputs": [],
      "source": [
        "timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "model_filename = f\"model_{timestep_str}.keras\"\n",
        "model.save(model_filename)\n",
        "del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNp6pUZuddqC"
      },
      "source": [
        "## ğŸ“Š Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU00iEFcYi_X",
        "outputId": "a45e783e-650e-41b7-b464-061e0a281de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m314/314\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 55ms/step\n",
            "Predictions shape: (10022, 64, 128)\n"
          ]
        }
      ],
      "source": [
        "model = tfk.models.load_model(model_filename, custom_objects={\n",
        "        \"DownsizeLayer\": DownsizeLayer,\n",
        "        \"UpsizeLayer\": UpsizeLayer,\n",
        "        'dice_loss': dice_loss,\n",
        "        'focal_loss': focal_loss,\n",
        "        'weighted_loss': weighted_loss,\n",
        "        'combined_loss': combined_loss_wrapper(),\n",
        "        'unet_block': unet_block,\n",
        "        'dense_block': dense_block,\n",
        "        'par_dil_conv': par_dil_conv,\n",
        "        'bottleneck_layer': bottleneck_layer,\n",
        "        'se_block': se_block,\n",
        "        'MeanIoU': tfk.metrics.MeanIoU\n",
        "    }\n",
        ")\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "preds = np.argmax(preds, axis=-1)\n",
        "print(f\"Predictions shape: {preds.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KErlLGwOTsX6"
      },
      "source": [
        "## ğŸ’¾ Save the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPjMEKqZW5jX"
      },
      "outputs": [],
      "source": [
        "def y_to_df(y) -> pd.DataFrame:\n",
        "    n_samples = len(y)\n",
        "    y_flat = y.reshape(n_samples, -1)\n",
        "    df = pd.DataFrame(y_flat)\n",
        "    df[\"id\"] = np.arange(n_samples)\n",
        "    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
        "    return df[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s18kX1uDconq"
      },
      "outputs": [],
      "source": [
        "# Create the csv submission file\n",
        "timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n",
        "submission_filename = f\"submission_{timestep_str}.csv\"\n",
        "submission_df = y_to_df(preds)\n",
        "submission_df.to_csv(submission_filename, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dw_-hFm6bjY6",
        "d7IqZP5Iblna",
        "GN_cpHlSboXV",
        "A3VPMx3wpqVd",
        "2z6VS98FeMBD",
        "dsXRC_eIlqdY",
        "KEb5t0AgmfQc",
        "OVztd7_HgvOq",
        "vUpegWw8SLNr",
        "RNp6pUZuddqC",
        "KErlLGwOTsX6"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
