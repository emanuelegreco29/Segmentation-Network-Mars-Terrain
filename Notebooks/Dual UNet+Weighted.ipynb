{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw_-hFm6bjY6"
      },
      "source": [
        "## 🌐 Connect Colab to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2S4GWr3Uoa8",
        "outputId": "0d304f95-fab1-42a6-aa23-743f978f1bf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/[2024-2025] AN2DL Homework 2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")\n",
        "%cd /gdrive/My Drive\n",
        "%cd [2024-2025] AN2DL Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7IqZP5Iblna"
      },
      "source": [
        "## ⚙️ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CO6_Ft_8T56A"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "tfk.config.enable_unsafe_deserialization()\n",
        "from tensorflow.keras import layers as tfkl\n",
        "from tensorflow.keras.layers import Layer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from scipy.stats import mode\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "seed = 29\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Set seed for TensorFlow\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Reduce TensorFlow verbosity\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_cpHlSboXV"
      },
      "source": [
        "## ⏳ Load the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLaoDaG1V1Yg",
        "outputId": "aa0590ce-8461-43e2-979b-a22a8ef7bdef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training X shape: (2615, 64, 128)\n",
            "Training y shape: (2615, 64, 128)\n",
            "Test X shape: (10022, 64, 128)\n",
            "Input shape: (64, 128, 1)\n",
            "Number of classes: 5\n"
          ]
        }
      ],
      "source": [
        "data = np.load(\"mars_for_students.npz\")\n",
        "\n",
        "training_set = data[\"training_set\"]\n",
        "X_train = training_set[:, 0]\n",
        "y_train = training_set[:, 1]\n",
        "\n",
        "X_test = data[\"test_set\"]\n",
        "\n",
        "print(f\"Training X shape: {X_train.shape}\")\n",
        "print(f\"Training y shape: {y_train.shape}\")\n",
        "print(f\"Test X shape: {X_test.shape}\")\n",
        "\n",
        "# Add color channel and rescale pixels between 0 and 1\n",
        "X_train = X_train[..., np.newaxis] / 255.0\n",
        "X_test = X_test[..., np.newaxis] / 255.0\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "print(f\"Input shape: {input_shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3VPMx3wpqVd"
      },
      "source": [
        "## 🔍 Inspect the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y5_2vtLTpufm",
        "outputId": "8bdebc81-a6c1-45bb-be5b-bb63972be4fa"
      },
      "outputs": [],
      "source": [
        "# Calculate prevalent labels\n",
        "y_train_labels = mode(y_train, axis=(1, 2))[0].flatten()\n",
        "\n",
        "print(f\"Shape X_train: {X_train.shape}\")\n",
        "print(f\"Shape y_train_labels: {y_train_labels.shape}\")\n",
        "\n",
        "# List all unique labels to check correctness\n",
        "unique_labels = np.unique(y_train)\n",
        "print(f\"Unique classes: {unique_labels}\")\n",
        "\n",
        "# Plot images in batches\n",
        "def plot_images(X, y, start_index=0, images_per_row=10, images_per_col=10):\n",
        "    fig, axes = plt.subplots(images_per_col, images_per_row, figsize=(15, 15))\n",
        "    for i in range(images_per_row * images_per_col):\n",
        "        idx = start_index + i\n",
        "        if idx >= len(X):\n",
        "            break\n",
        "        ax = axes[i // images_per_row, i % images_per_row]\n",
        "        ax.imshow(X[idx], cmap=\"gray\")\n",
        "        ax.set_title(f\"Class: {y[idx]}\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot a sample image from each class\n",
        "def plot_one_sample_per_class(X, y, y_mask, classes):\n",
        "    for label in classes:\n",
        "        for i in range(len(y_mask)):\n",
        "            if label in np.unique(y_mask[i]):\n",
        "                plt.figure()\n",
        "                plt.imshow(X[i], cmap=\"gray\")\n",
        "                plt.title(f\"Class: {label}\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.show()\n",
        "                break\n",
        "\n",
        "plot_one_sample_per_class(X_train, y_train_labels, y_train, unique_labels)\n",
        "\n",
        "# Plot all images\n",
        "images_per_row = 10\n",
        "images_per_col = 10\n",
        "images_per_page = images_per_row * images_per_col\n",
        "num_images = X_train.shape[0]\n",
        "\n",
        "for start_idx in range(0, num_images, images_per_page):\n",
        "    plot_images(X_train, y_train_labels, start_index=start_idx, images_per_row=images_per_row, images_per_col=images_per_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z6VS98FeMBD"
      },
      "source": [
        "## ❌ Remove outliers from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PzVZbyNco6v",
        "outputId": "34944329-654c-4d6f-dcfd-00f547481608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X_train_filtered: (2505, 64, 128, 1)\n",
            "Shape y_train_filtered: (2505, 64, 128)\n",
            "Unique classes: [0. 1. 2. 3. 4.]\n"
          ]
        }
      ],
      "source": [
        "# Lists to contain filtered elements\n",
        "X_train_filtered = []\n",
        "y_train_filtered = []\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "    label = y_train[i].argmax() if y_train.ndim > 1 else y_train[i]\n",
        "    if label != 415:\n",
        "        # Add to filtered dataset the non-alien images\n",
        "        X_train_filtered.append(X_train[i])\n",
        "        y_train_filtered.append(y_train[i])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train_filtered = np.array(X_train_filtered)\n",
        "y_train_filtered = np.array(y_train_filtered)\n",
        "\n",
        "print(f\"Shape X_train_filtered: {X_train_filtered.shape}\")\n",
        "print(f\"Shape y_train_filtered: {y_train_filtered.shape}\")\n",
        "print(f\"Unique classes: {np.unique(y_train_filtered)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fE76Lu-Ea0-"
      },
      "source": [
        "## 🔍 Inspect the filtered training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ibagIaQkHRiK",
        "outputId": "791cda09-aefa-43f4-c7a5-e7da21f103bf"
      },
      "outputs": [],
      "source": [
        "num_images_filtered = X_train_filtered.shape[0]\n",
        "y_train_filtered_labels = mode(y_train_filtered, axis=(1, 2))[0].flatten()\n",
        "\n",
        "# Plot the filtered dataset\n",
        "for start_idx in range(0, num_images_filtered, images_per_page):\n",
        "    plot_images(X_train_filtered, y_train_filtered_labels, start_index=start_idx, images_per_row=images_per_row, images_per_col=images_per_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsXRC_eIlqdY"
      },
      "source": [
        "## 🧮 Define network parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB8MXxkwltdh"
      },
      "outputs": [],
      "source": [
        "# Set batch size for training\n",
        "batch_size = 64\n",
        "\n",
        "# Set learning rate for the optimizer\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Set early stopping patience threshold\n",
        "patience = 15\n",
        "\n",
        "# Set maximum number of training epochs\n",
        "epochs = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te5Ey7pNoeiw"
      },
      "outputs": [],
      "source": [
        "# Create an EarlyStopping callback\n",
        "early_stopping = tfk.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=patience,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Create a LearningRate Scheduler, which reduces learning rate if val_loss doesn't improve\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5\n",
        ")\n",
        "\n",
        "# Store the callback in a list\n",
        "callbacks = [early_stopping, lr_scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEb5t0AgmfQc"
      },
      "source": [
        "## ✂ Split into Training and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVf9fnTumtuP",
        "outputId": "a08d1cc2-e829-41ca-ff57-660926d0caaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape:\t (2254, 64, 128, 1) (2254, 64, 128)\n",
            "Validation set shape:\t (251, 64, 128, 1) (251, 64, 128)\n",
            "Class weights:\t [0.8176698618113929, 0.5910939761597104, 0.8421959857784994, 1.1219193842338118, 153.08214226496435]\n"
          ]
        }
      ],
      "source": [
        "# Split the training dataset to get a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_filtered,\n",
        "    y_train_filtered,\n",
        "    test_size=0.1,\n",
        "    random_state=seed)\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "class_weights = [class_weights[key] for key in sorted(class_weights.keys())]\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print('Training set shape:\\t', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:\\t', X_val.shape, y_val.shape)\n",
        "print('Class weights:\\t', class_weights)\n",
        "\n",
        "# Convert in un tensore statico\n",
        "class_weights = tf.constant(class_weights, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVztd7_HgvOq"
      },
      "source": [
        "## 🔄 Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_laNhjCPgxQo"
      },
      "outputs": [],
      "source": [
        "def augment_data(image, label):\n",
        "    # Geometric Transformations\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    label = tf.image.random_flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    label = tf.image.random_flip_up_down(label)\n",
        "\n",
        "    # Chromatic Transformations\n",
        "    image = tf.image.random_brightness(image, max_delta=0.4)\n",
        "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = tf.expand_dims(image, axis=-1) if len(image.shape) == 2 else image\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "def preprocess_label(label):\n",
        "    label = tf.expand_dims(label, axis=-1) if len(label.shape) == 2 else label\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    return label\n",
        "\n",
        "def preprocess_data(image, label):\n",
        "    image = preprocess_image(image)\n",
        "    label = preprocess_label(label)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnFLkc1chG53"
      },
      "outputs": [],
      "source": [
        "# Original dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Augmented dataset\n",
        "augmented_dataset = train_dataset.map(lambda x, y: augment_data(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Combined dataset, having both augmented and original dataset\n",
        "combined_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "combined_dataset = combined_dataset.shuffle(buffer_size=len(X_train))\n",
        "combined_dataset = combined_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation dataset\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzyhdlxCF2-X"
      },
      "source": [
        "## 🔍 Plot Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "BIprDuBhF3-p",
        "outputId": "692913ee-e0f8-46ff-d9f1-cf9c397420e9"
      },
      "outputs": [],
      "source": [
        "def plot_from_dataset(dataset, title, num_images=10):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 3))\n",
        "    fig.suptitle(title, fontsize=16, y=1.05)\n",
        "    count = 0\n",
        "\n",
        "    for batch in dataset:\n",
        "        images, label_maps = batch\n",
        "        for i in range(len(images)):\n",
        "            if count >= num_images:\n",
        "                break\n",
        "            image = images[i].numpy()\n",
        "            if image.shape[-1] == 1:\n",
        "                image = tf.squeeze(image, axis=-1).numpy()\n",
        "            axes[count].imshow(image, cmap='gray' if image.ndim == 2 else None, aspect='auto')\n",
        "            axes[count].axis('off')\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        if count >= num_images:\n",
        "            break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_from_dataset(train_dataset, \"Train Dataset without Augmentation\", num_images=10)\n",
        "plot_from_dataset(augmented_dataset, \"Train Dataset with Augmentation\", num_images=10)\n",
        "plot_from_dataset(combined_dataset, \"Combined Dataset\", num_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUpegWw8SLNr"
      },
      "source": [
        "## 🔨 Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH96h-n22oOo"
      },
      "outputs": [],
      "source": [
        "def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
        "    # Residual connection\n",
        "    residual = input_tensor\n",
        "    residual = tfkl.Conv2D(filters, kernel_size=1, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(residual)\n",
        "\n",
        "    # Convolutional path\n",
        "    x = input_tensor\n",
        "    for i in range(stack):\n",
        "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "        x = tfkl.BatchNormalization()(x)\n",
        "        x = tfkl.Activation(activation)(x)\n",
        "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "        x = tfkl.BatchNormalization()(x)\n",
        "        x = tfkl.Activation(activation)(x)\n",
        "        x = tfkl.SpatialDropout2D(0.2)(x)\n",
        "\n",
        "    # Add residual connection\n",
        "    x = tfkl.Add()([x, residual])\n",
        "    return x\n",
        "\n",
        "def dense_block(input_tensor, filters, kernel_size=3, growth_rate=32, num_layers=4):\n",
        "    x = input_tensor\n",
        "    for i in range(num_layers):\n",
        "        conv = tfkl.Conv2D(growth_rate, kernel_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "        conv = tfkl.BatchNormalization()(conv)\n",
        "        conv = tfkl.Activation('relu')(conv)\n",
        "        x = tfkl.Concatenate()([x, conv])\n",
        "    return x\n",
        "\n",
        "def par_dil_conv(input_tensor, filters, kernel_size=3, dilation_rates=(1, 2, 4), activation='relu'):\n",
        "    branches = []\n",
        "    for rate in dilation_rates:\n",
        "        branch = tfkl.Conv2D(filters, kernel_size=kernel_size, dilation_rate=rate, padding='same',\n",
        "                             kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(input_tensor)\n",
        "        branch = tfkl.BatchNormalization()(branch)\n",
        "        branch = tfkl.Activation(activation)(branch)\n",
        "        branches.append(branch)\n",
        "    output = tfkl.Concatenate()(branches)\n",
        "    output = tfkl.Conv2D(filters, kernel_size=1, padding='same', kernel_initializer='he_normal')(output)\n",
        "    return output\n",
        "\n",
        "def bottleneck_layer(input_tensor, filters, reduction_ratio=4, dilation_rates=(1, 2, 4)):\n",
        "    # Compression\n",
        "    reduced_filters = filters // reduction_ratio\n",
        "    bottleneck = tfkl.Conv2D(reduced_filters, kernel_size=1, padding='same', activation='relu')(input_tensor)\n",
        "\n",
        "    # Parallel Dilated Convolutions\n",
        "    bottleneck = par_dil_conv(bottleneck, filters=reduced_filters, dilation_rates=dilation_rates)\n",
        "\n",
        "    # Expansion\n",
        "    bottleneck = tfkl.Conv2D(filters, kernel_size=3, padding='same', activation='relu')(bottleneck)\n",
        "    return bottleneck\n",
        "\n",
        "def se_block(input_tensor, reduction_ratio=16):\n",
        "    filters = input_tensor.shape[-1]\n",
        "    se = tfkl.GlobalAveragePooling2D()(input_tensor)\n",
        "    se = tfkl.Dense(filters // reduction_ratio, activation='relu')(se)\n",
        "    se = tfkl.Dense(filters, activation='sigmoid')(se)\n",
        "    se = tfkl.Reshape((1, 1, filters))(se)\n",
        "    return tfkl.Multiply()([input_tensor, se])\n",
        "\n",
        "# Class to downsize a tensor\n",
        "class DownsizeLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.image.resize(inputs, (32, 64))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], 32, 64, input_shape[-1])\n",
        "\n",
        "# Class to upsize a tensor\n",
        "class UpsizeLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.image.resize(inputs, (64, 128))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], 64, 128, input_shape[-1])\n",
        "\n",
        "# Function to create a UNet\n",
        "def create_unet(input_shape, num_classes):\n",
        "  input_layer = tfkl.Input(shape=input_shape)\n",
        "\n",
        "  # Downsampling path\n",
        "  down_block_1 = dense_block(input_layer, filters=32, growth_rate=16, num_layers=3)\n",
        "  d1 = tfkl.Conv2D(32, (3, 3), strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(1e-4))(down_block_1)\n",
        "\n",
        "  down_block_2 = dense_block(d1, filters=64, growth_rate=16, num_layers=3)\n",
        "  d2 = tfkl.Conv2D(64, (3, 3), strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(1e-4))(down_block_2)\n",
        "\n",
        "  # Bottleneck con Parallel Dilated Convolutions\n",
        "  bottleneck = bottleneck_layer(d2, filters=128, dilation_rates=(1, 2, 4))\n",
        "  bottleneck = se_block(bottleneck)\n",
        "\n",
        "  # Upsampling path\n",
        "  u1 = tfkl.Conv2DTranspose(64, kernel_size=2, strides=2, padding='same')(bottleneck)\n",
        "  u1 = tfkl.Concatenate()([u1, se_block(down_block_2)])\n",
        "  u1 = unet_block(u1, 64, name='up_block1_')\n",
        "\n",
        "  u2 = tfkl.Conv2DTranspose(32, kernel_size=2, strides=2, padding='same')(u1)\n",
        "  u2 = tfkl.Concatenate()([u2, se_block(down_block_1)])\n",
        "  u2 = unet_block(u2, 32, name='up_block2_')\n",
        "\n",
        "  # Output Layer\n",
        "  output_layer = se_block(u2)\n",
        "  output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\")(output_layer)\n",
        "\n",
        "  return tfk.Model(inputs=input_layer, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e2Mz9gUVbGd"
      },
      "outputs": [],
      "source": [
        "# Dice Loss\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    if len(y_true.shape) < len(y_pred.shape):\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])\n",
        "\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    tf.debugging.assert_equal(\n",
        "    tf.shape(y_true),\n",
        "    tf.shape(y_pred),\n",
        "    message=\"Shape mismatch: y_true and y_pred have different shapes.\"\n",
        ")\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return 1 - ((2. * intersection + smooth) /\n",
        "                (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth))\n",
        "\n",
        "# Focal Loss\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
        "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])\n",
        "        y_true_one_hot = tf.squeeze(y_true_one_hot, axis=-2) if len(y_true_one_hot.shape) > len(y_pred.shape) else y_true_one_hot\n",
        "        cross_entropy = -y_true_one_hot * tf.keras.backend.log(y_pred)\n",
        "        weight = alpha * tf.math.pow((1 - y_pred), gamma)\n",
        "        loss = weight * cross_entropy\n",
        "        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n",
        "\n",
        "    return focal_loss_fixed\n",
        "\n",
        "def weighted_loss(y_true, y_pred):\n",
        "    global class_weights\n",
        "    weights_per_pixel = tf.gather(class_weights, tf.cast(y_true, tf.int32))\n",
        "    weights_per_pixel = tf.expand_dims(weights_per_pixel, axis=-1)\n",
        "    weights_per_pixel = tf.squeeze(weights_per_pixel, axis=-1)\n",
        "\n",
        "    # Calculate SparseCategoricalCrossentropy\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
        "    unweighted_loss = scce(y_true, y_pred)\n",
        "\n",
        "    # To match dimensions\n",
        "    unweighted_loss = tf.expand_dims(unweighted_loss, axis=-1)\n",
        "\n",
        "    weighted_loss = unweighted_loss * weights_per_pixel\n",
        "\n",
        "    # Media finale\n",
        "    return tf.reduce_mean(weighted_loss)\n",
        "\n",
        "focal = focal_loss(gamma=2.0, alpha=0.25)\n",
        "\n",
        "# Combined Loss\n",
        "def combined_loss_wrapper():\n",
        "    def combined_loss(y_true, y_pred):\n",
        "        # Weighted Loss\n",
        "        w_loss = weighted_loss(y_true, y_pred)\n",
        "\n",
        "        # Dice Loss\n",
        "        d_loss = dice_loss(y_true, y_pred)\n",
        "\n",
        "        # Focal Loss\n",
        "        f_loss = focal(y_true, y_pred)\n",
        "\n",
        "        # Somma delle perdite\n",
        "        return w_loss + d_loss + f_loss\n",
        "\n",
        "    return combined_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CBkb3TRF1KJx"
      },
      "outputs": [],
      "source": [
        "downsize_layer = DownsizeLayer()\n",
        "upsize_layer = UpsizeLayer()\n",
        "\n",
        "# Global UNet\n",
        "input_shape_global = (32, 64, 1)\n",
        "unet_global = create_unet(input_shape_global, num_classes)\n",
        "\n",
        "# Local UNet\n",
        "unet_local = create_unet(input_shape, num_classes)\n",
        "\n",
        "# Input\n",
        "inputs = tfkl.Input(shape=input_shape)\n",
        "\n",
        "global_input = downsize_layer(inputs)\n",
        "global_features = unet_global(global_input)\n",
        "\n",
        "local_features = unet_local(inputs)\n",
        "\n",
        "# Features fusion from both nets\n",
        "global_upsampled = upsize_layer(global_features) # Upsize to match dimensions\n",
        "fused_features = tfkl.Concatenate()([global_upsampled, local_features])\n",
        "\n",
        "output = tfkl.Conv2D(num_classes, kernel_size=3, padding='same', activation='softmax')(fused_features)\n",
        "\n",
        "model = tfk.Model(inputs, output)\n",
        "\n",
        "# Define the MeanIoU ignoring the background class\n",
        "mean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False, name='mean_iou')\n",
        "optimizer = tfk.optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-5)\n",
        "loss = weighted_loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=[mean_iou]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSliIxBvbs2Q"
      },
      "source": [
        "## 🛠️ Train and Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMCbSMQ_-XoH",
        "outputId": "f55ff831-f494-4663-cc75-7ed21f2ee576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 1s/step - loss: 1.7909 - mean_iou: 0.1287 - val_loss: 1.9444 - val_mean_iou: 0.1115 - learning_rate: 1.0000e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 242ms/step - loss: 1.7848 - mean_iou: 0.1623 - val_loss: 1.9532 - val_mean_iou: 0.1079 - learning_rate: 1.0000e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 242ms/step - loss: 1.7407 - mean_iou: 0.1614 - val_loss: 1.9729 - val_mean_iou: 0.0866 - learning_rate: 1.0000e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 246ms/step - loss: 1.7627 - mean_iou: 0.1794 - val_loss: 1.9622 - val_mean_iou: 0.0789 - learning_rate: 1.0000e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 247ms/step - loss: 1.7187 - mean_iou: 0.1928 - val_loss: 1.9490 - val_mean_iou: 0.1130 - learning_rate: 1.0000e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - loss: 1.6495 - mean_iou: 0.2064 - val_loss: 1.6568 - val_mean_iou: 0.1563 - learning_rate: 1.0000e-04\n",
            "Epoch 7/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 248ms/step - loss: 1.6148 - mean_iou: 0.2351 - val_loss: 1.6199 - val_mean_iou: 0.2504 - learning_rate: 1.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - loss: 1.6044 - mean_iou: 0.2588 - val_loss: 1.5256 - val_mean_iou: 0.2529 - learning_rate: 1.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - loss: 1.4522 - mean_iou: 0.2798 - val_loss: 1.4966 - val_mean_iou: 0.2507 - learning_rate: 1.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - loss: 1.5152 - mean_iou: 0.2770 - val_loss: 1.5876 - val_mean_iou: 0.2651 - learning_rate: 1.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - loss: 1.4488 - mean_iou: 0.2889 - val_loss: 1.4995 - val_mean_iou: 0.2589 - learning_rate: 1.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - loss: 1.4281 - mean_iou: 0.2997 - val_loss: 1.5242 - val_mean_iou: 0.2426 - learning_rate: 1.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - loss: 1.4031 - mean_iou: 0.3064 - val_loss: 1.5353 - val_mean_iou: 0.1618 - learning_rate: 1.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 248ms/step - loss: 1.4576 - mean_iou: 0.2911 - val_loss: 1.3843 - val_mean_iou: 0.3089 - learning_rate: 1.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - loss: 1.3325 - mean_iou: 0.3219 - val_loss: 1.3433 - val_mean_iou: 0.3563 - learning_rate: 1.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - loss: 1.3623 - mean_iou: 0.3255 - val_loss: 1.3215 - val_mean_iou: 0.3342 - learning_rate: 1.0000e-04\n",
            "Epoch 17/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - loss: 1.3131 - mean_iou: 0.3453 - val_loss: 1.3027 - val_mean_iou: 0.3598 - learning_rate: 1.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - loss: 1.3128 - mean_iou: 0.3407 - val_loss: 1.3502 - val_mean_iou: 0.3325 - learning_rate: 1.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 249ms/step - loss: 1.2589 - mean_iou: 0.3578 - val_loss: 1.3612 - val_mean_iou: 0.3122 - learning_rate: 1.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - loss: 1.2940 - mean_iou: 0.3664 - val_loss: 1.2404 - val_mean_iou: 0.3808 - learning_rate: 1.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 247ms/step - loss: 1.2176 - mean_iou: 0.3684 - val_loss: 1.3950 - val_mean_iou: 0.3130 - learning_rate: 1.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - loss: 1.2289 - mean_iou: 0.3503 - val_loss: 1.1823 - val_mean_iou: 0.4316 - learning_rate: 1.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - loss: 1.2147 - mean_iou: 0.3748 - val_loss: 1.2281 - val_mean_iou: 0.4072 - learning_rate: 1.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 247ms/step - loss: 1.2208 - mean_iou: 0.3747 - val_loss: 1.3262 - val_mean_iou: 0.3161 - learning_rate: 1.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - loss: 1.1329 - mean_iou: 0.4023 - val_loss: 1.3656 - val_mean_iou: 0.3764 - learning_rate: 1.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - loss: 1.1230 - mean_iou: 0.3962 - val_loss: 1.2954 - val_mean_iou: 0.3587 - learning_rate: 1.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 247ms/step - loss: 1.1321 - mean_iou: 0.3892 - val_loss: 1.4391 - val_mean_iou: 0.3326 - learning_rate: 1.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 247ms/step - loss: 1.1108 - mean_iou: 0.4044 - val_loss: 1.3457 - val_mean_iou: 0.3939 - learning_rate: 5.0000e-05\n",
            "Epoch 29/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - loss: 1.0825 - mean_iou: 0.4249 - val_loss: 1.1386 - val_mean_iou: 0.3978 - learning_rate: 5.0000e-05\n",
            "Epoch 30/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - loss: 1.0863 - mean_iou: 0.4189 - val_loss: 1.2951 - val_mean_iou: 0.3815 - learning_rate: 5.0000e-05\n",
            "Epoch 31/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 247ms/step - loss: 1.0359 - mean_iou: 0.4311 - val_loss: 1.3630 - val_mean_iou: 0.3693 - learning_rate: 5.0000e-05\n",
            "Epoch 32/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - loss: 1.0504 - mean_iou: 0.4244 - val_loss: 1.3179 - val_mean_iou: 0.3944 - learning_rate: 5.0000e-05\n",
            "Epoch 33/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 246ms/step - loss: 1.0249 - mean_iou: 0.4377 - val_loss: 1.3180 - val_mean_iou: 0.3911 - learning_rate: 5.0000e-05\n",
            "Epoch 34/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 247ms/step - loss: 1.0482 - mean_iou: 0.4400 - val_loss: 1.2949 - val_mean_iou: 0.3859 - learning_rate: 5.0000e-05\n",
            "Epoch 35/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 246ms/step - loss: 1.0288 - mean_iou: 0.4416 - val_loss: 1.3470 - val_mean_iou: 0.3797 - learning_rate: 2.5000e-05\n",
            "Epoch 36/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - loss: 1.0418 - mean_iou: 0.4270 - val_loss: 1.2524 - val_mean_iou: 0.3880 - learning_rate: 2.5000e-05\n",
            "Epoch 37/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - loss: 1.0325 - mean_iou: 0.4397 - val_loss: 1.2530 - val_mean_iou: 0.3985 - learning_rate: 2.5000e-05\n",
            "Epoch 38/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - loss: 0.9964 - mean_iou: 0.4356 - val_loss: 1.3335 - val_mean_iou: 0.3854 - learning_rate: 2.5000e-05\n",
            "Epoch 39/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - loss: 1.0044 - mean_iou: 0.4453 - val_loss: 1.3652 - val_mean_iou: 0.3747 - learning_rate: 2.5000e-05\n",
            "Epoch 40/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - loss: 0.9920 - mean_iou: 0.4544 - val_loss: 1.3376 - val_mean_iou: 0.3767 - learning_rate: 1.2500e-05\n",
            "Epoch 41/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - loss: 1.0071 - mean_iou: 0.4409 - val_loss: 1.2738 - val_mean_iou: 0.3848 - learning_rate: 1.2500e-05\n",
            "Epoch 42/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 253ms/step - loss: 0.9928 - mean_iou: 0.4445 - val_loss: 1.3165 - val_mean_iou: 0.3787 - learning_rate: 1.2500e-05\n",
            "Epoch 43/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - loss: 1.0050 - mean_iou: 0.4508 - val_loss: 1.3209 - val_mean_iou: 0.3766 - learning_rate: 1.2500e-05\n",
            "Epoch 44/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - loss: 0.9587 - mean_iou: 0.4587 - val_loss: 1.3257 - val_mean_iou: 0.3837 - learning_rate: 1.2500e-05\n",
            "Final validation Mean Intersection Over Union: 43.16%\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    combined_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks\n",
        ").history\n",
        "\n",
        "# Calculate and print the final validation accuracy\n",
        "final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n",
        "print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtM0ubgdOzG-"
      },
      "outputs": [],
      "source": [
        "timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "model_filename = f\"model_{timestep_str}.keras\"\n",
        "model.save(model_filename)\n",
        "del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNp6pUZuddqC"
      },
      "source": [
        "## 📊 Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU00iEFcYi_X",
        "outputId": "af28d444-4bf1-418c-8859-63596aeea37e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step\n",
            "Predictions shape: (10022, 64, 128)\n"
          ]
        }
      ],
      "source": [
        "model = tfk.models.load_model(model_filename, custom_objects={\n",
        "        \"DownsizeLayer\": DownsizeLayer,\n",
        "        \"UpsizeLayer\": UpsizeLayer,\n",
        "        'dice_loss': dice_loss,\n",
        "        'focal_loss': focal_loss,\n",
        "        'weighted_loss': weighted_loss,\n",
        "        'combined_loss': combined_loss_wrapper(),\n",
        "        'unet_block': unet_block,\n",
        "        'dense_block': dense_block,\n",
        "        'par_dil_conv': par_dil_conv,\n",
        "        'bottleneck_layer': bottleneck_layer,\n",
        "        'se_block': se_block,\n",
        "        'MeanIoU': tfk.metrics.MeanIoU\n",
        "    }\n",
        ")\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "preds = np.argmax(preds, axis=-1)\n",
        "print(f\"Predictions shape: {preds.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KErlLGwOTsX6"
      },
      "source": [
        "## 💾 Save the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPjMEKqZW5jX"
      },
      "outputs": [],
      "source": [
        "def y_to_df(y) -> pd.DataFrame:\n",
        "    n_samples = len(y)\n",
        "    y_flat = y.reshape(n_samples, -1)\n",
        "    df = pd.DataFrame(y_flat)\n",
        "    df[\"id\"] = np.arange(n_samples)\n",
        "    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
        "    return df[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s18kX1uDconq"
      },
      "outputs": [],
      "source": [
        "# Create the csv submission file\n",
        "timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n",
        "submission_filename = f\"submission_{timestep_str}.csv\"\n",
        "submission_df = y_to_df(preds)\n",
        "submission_df.to_csv(submission_filename, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dw_-hFm6bjY6",
        "d7IqZP5Iblna",
        "GN_cpHlSboXV",
        "A3VPMx3wpqVd",
        "2z6VS98FeMBD",
        "dsXRC_eIlqdY",
        "KEb5t0AgmfQc",
        "OVztd7_HgvOq",
        "vUpegWw8SLNr",
        "RNp6pUZuddqC",
        "KErlLGwOTsX6"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
